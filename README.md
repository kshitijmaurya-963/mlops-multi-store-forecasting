# ğŸ›’ MLOps Multi-Store Forecasting

An **end-to-end MLOps project** for **retail sales forecasting across multiple stores & SKUs**.  
This repository demonstrates how to design, build, and deploy a **production-grade ML pipeline** including:

- ğŸ“Š **Feature Engineering** with rolling aggregates & lag-based predictors  
- ğŸ” **Rolling Backtesting** for robust model evaluation  
- ğŸŒ² **Random Forest Regressor (baseline)** â€“ extendable to advanced models (XGBoost, LSTM, Transformer)  
- âš¡ **FastAPI Model Serving** with REST endpoints  
- ğŸ“ˆ **Streamlit Dashboard** for interactive forecasting exploration  
- ğŸ³ **Dockerized Workflows** for training & serving pipelines  
- ğŸ”§ **MLOps Best Practices**: experiment tracking, artifact management, reproducible builds  

---

**ğŸš€ Project Structure**
```bash
mlops-multi-store-forecasting/
â”‚
â”œâ”€â”€ data/                # Input datasets (per store & SKU)
â”œâ”€â”€ artifacts/           # Trained models, metrics, logs
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ features.py      # Feature engineering pipeline
â”‚   â”œâ”€â”€ train_backtest.py # Rolling backtesting & training
â”‚   â”œâ”€â”€ serve.py         # FastAPI inference service
â”‚   â”œâ”€â”€ dashboard.py     # Streamlit dashboard for exploration
â”‚   â””â”€â”€ utils.py         # Helper functions
â”‚
â”œâ”€â”€ Dockerfile.train     # Docker image for training jobs
â”œâ”€â”€ Dockerfile.serve     # Docker image for serving API
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # Project documentation
```
---
**âš¡ Quickstart**
1. Create a virtual env and install requirements:
   ```bash
   python -m venv venv
   source venv/bin/activate   # Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```
2. Generate sample data:
   ```bash
   python src/data_generation.py --out_dir data/
   ```
3. Run rolling training/backtest:
   ```bash
   python -m src.train_backtest --data_dir data/ --out artifacts/
   ```
4. Serve a saved model (registry/v1):
   ```bash
   cd src && uvicorn serve:app --host 0.0.0.0 --port 8000
   ```
   Endpoint: POST http://127.0.0.1:8000/predict

   Example request:
   {
     "store_id": 1,
     "sku": 42,
     "date": "2025-09-01",
     "features": {...}
   }
5. Run monitoring job (writes `artifacts/monitoring.json`):
   ```bash
   python src/monitoring.py --data_dir data/ --models_dir registry/ --out artifacts/monitoring.json
   ```

6. Explore with Streamlit Dashboard
   ```bash
   streamlit run src/dashboard.py
   ```
**ğŸ³ Dockerized Workflows**
1. Training
   ```bash
   docker build -f Dockerfile.train -t mlops-forecast-train:latest .
   docker run --rm -v ${PWD}/data:/app/data -v ${PWD}/artifacts:/app/artifacts mlops-forecast-train:latest
   ```
2. Serving
   ```bash
   docker build -f Dockerfile.serve -t mlops-forecast-serve:latest .
   docker run -p 8000:8000 mlops-forecast-serve:latest
   ```
---
**ğŸ› ï¸ Tech Stack**  
- Python (pandas, scikit-learn, numpy)  
- FastAPI for model serving  
- Streamlit for dashboarding  
- Docker for containerized workflows  
- MLflow / JSON Artifacts for tracking experiments (extensible)  
---
**ğŸ”® Future Scope**  
âœ… Integrate XGBoost / LightGBM / Deep Learning models  
âœ… Add MLflow experiment tracking  
âœ… CI/CD with GitHub Actions  
âœ… Kubernetes deployment for scalable inference  

---
**ğŸ¤ Contributing**  
PRs are welcome! For major changes, please open an issue first to discuss what youâ€™d like to change.  

---
**ğŸ‘¨â€ğŸ’» Author**  
Kshitij Maurya  
Data Scientist | AI/ML Engineer | Product Thinker  
